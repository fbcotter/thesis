\begin{table}
  \renewcommand{\arraystretch}{1.2}
  \centering
  \caption{Results for testing VGG like architecture with convolutional and
  invariant layers on several datasets. An architecture with `invX' means the
  equivalent convolutional layer `convX' from \autoref{tab:arch} was swapped for
  our proposed layer. The top row is the reference architecture using all
  convolutional layers. The `A' architecture is the originally proposed gain
  layer, the `B' architecture uses the gainlayer with random shifting of the
  activations, and the `C' architecture changes the mixing to be a learned
  $3\x3$ kernel acting on the invariant coefficients. Numbers are averages over
  5 runs.}
  % \begin{tabular}{@{}lllcllcll@{}}
  \begin{tabular}{@{}lccclccclccc@{}}
    \toprule
    & \multicolumn{3}{c}{CIFAR-10} & \phantom{abc} & \multicolumn{3}{c}{CIFAR-100} & \phantom{abc} & \multicolumn{3}{c}{Tiny ImgNet} \\ \cline{2-4}\cline{6-8}\cline{10-12}
    \phantom{abc} & A  & B & C &&  A & B & C && A & B & C \\ \midrule
    reference & 92.6 & - & - && 70.3 & - & - && 59.1 & - & - \\ \midrule
    invA & 92.3 & 92.4 & 92.3 && 69.5 & & && 57.7 & &  \\
    invB & 93.4 & 93.2 & 93.4 && 70.7 & & && 59.5 & &  \\
    invC & 93.7 & 93.2 & 93.4 && 71.2 & & && 59.8 & &  \\
    invD & 92.7 & 92.6 & 92.8 && 70.1 & & && 59.3 & &  \\
    invE & 91.8 & 92.2 & 92.5 && 70.0 & & && 59.4 & &  \\
    invF & 92.4 & 92.9 & && 68.9 & & && 57.8 & &  \\
    invA, invB& 92.6 & 91.8 & 92.4 && 68.4 & &  && 57.9 & & \\
    invB, invC& 92.2 & 91.8 & 92.3 && 69.1 & & && 57.5 & & \\
    invC, invD& 92.5 & 92.0 & 92.9 && 70.1 & &  && 59.0 & & \\
    invD, invE& 90.4 & 91.2 & 91.9 && 67.3 & &  && 57.5 & & \\
    invA, invC& 92.2 & 92.0 & 92.5 && 69.6 & &  && 56.9 & & \\
    invB, invD& 92.8 & 92.3 & 82.8 && 71.3 & &  && 59.8 & & \\
    invC, invE& 91.5 & 92.0 & 92.3 && 70.9 & &  && 60.2 & & \\ \bottomrule
  \end{tabular}\label{tab:conv_results}
\end{table}

