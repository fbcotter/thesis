\section{Method}\label{sec:ch6:method}

\section{Aliasing in the DWT}
Consider a single level critically sampled DWT in 1-D. The aliasing cancelling
condition is:

$$G_0(z)H_0(-z) + G_1(z)H_1(-z) = 0$$

This is typically solved by using Quadrature Mirror Filters, i.e.

\begin{align}
  H_1(z) &= H_0(-z) \\
  G_0(z) &= H_0(z) \\
  G_1(z) &= -H_1(z) = -H_0(-z) 
\end{align}

\section{Shift Invariance of the $\DTCWT$}
\begin{figure}
  \includegraphics[width=\textwidth]{\imgpath/dtcwt.png}
  \mycaption{Full 1-D $\DTCWT$}{}
\end{figure}

\begin{figure}
  \centering
  \input{\imgpath/dtcwt}
  \mycaption{Block Diagram of 1-D $\DTCWT$}{Note the top and bottom paths are
  through the wavelet or scaling functions from just level m ($M=2^m$). Figure
  based on Figure~4 in \cite{kingsbury_complex_2001}.}
  \label{fig:dtcwt_two_tree}
\end{figure}

Firstly, let us look at what would happen if we retained only 1 of the subbands.
Note that we have to keep the same band from each tree. E.g. if we wanted to
keep the $x_{001}$ coefficients, we must keep $x_{001a}$ and $x_{001b}$. For any
pair of coefficients on the tree, this would look like:

e.g. if we kept $x_{001a}$ and $x_{001b}$ then $M=8$ and $A(z) =
H_{0a}(z)H_{00a}(z^2)H_{001a}(z^4)$ is the transfer fucntion from $x$ to
$x_{001a}$. The transfer functions for $B(z)$, $C(z)$ and $D(z)$ are obtained
similarly. It is well known that:

\begin{eqnarray}
  U(z) \downarrow M &\rightarrow&  U(z^M) \\
  U(z) \uparrow M &\rightarrow & \frac{1}{M}\sum_{k=0}^{M-1}U(W^kz^{1/M})
\end{eqnarray}

Where $W=e^{j2\pi/M}$. So downsampling followed by upsampling becomes:
$$U(z) \downarrow M \uparrow M \rightarrow \frac{1}{M}\sum_{k=0}^{M-1}U(W^kz)$$

This means that

  $$Y(z) = Y_{a}(z) + Y_{b}(z) = \frac{1}{M} \sum_{k=0}^{M-1} X(W^k z) [A(W^kz)C(z) + B(W^kz)D(z)]$$

The aliasing terms for which are everywhere where $k \neq 0$ (as $X(W^kz)$ is
$X(z)$ shifted by $\frac{2k\pi}{M}$). I.e. to avoid aliasing in this reduced
tree, we want to make sure that $A(W^kz)C(z) + B(W^kz)D(z) = 0$ for all $k \neq
0$.

The figure below (Fig 5 from \cite{kingsbury_complex_2001}) shows what $A(W^kz)$
and $C(z)$ look like for both the lowpass case (left) and the highpass case
(right). Note that these responses will be similar for $B(W^kz)$ and $D(z)$. For
large values of k, there is almost no overlap (i.e. 
$A(W^kz)C(z) \approx B(W^kz)D(z) \approx 0$, 
but for small values of k (particularly $k = \pm 1$),
the transition bands have significant overlap with the central response. It is
here that we need to use the flexibility of having 2 trees to ensure that
$A(W^kz)C(z)$ and $B(W^kz)D(z)$ cancel out.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{\imgpath/overlaps.png}
\end{figure}

To do this, let us consider the lowpass filters first. If we let:

\begin{eqnarray}
  B(z) &=& z^{\pm M/2}A(z) \\
  D(z) &=& z^{\mp M/2}C(z)
\end{eqnarray}

Then

\begin{eqnarray}
  A(W^kz)C(z) + B(W^kz)D(z) &=& A(W^kz)C(z) + (W^kz)^{\pm M/2}A(W^kz) z^{\mp M/2}C(z) \\
  &=& A(W^kz)C(z) + e^{\frac{jk2\pi}{M} \times (\pm \frac{M}{2})} z^{\pm M/2} z^{\mp M/2} A(W^kz)C(z) \\
  &=& A(W^kz)C(z) + (-1)^k A(W^kz)C(z)
\end{eqnarray}

Which cancels when k is odd

Now consider the bandpass case. For shifts of $k=1$ the right half of the left
peak overlaps with the left half of the right peak. For a shift of $k=2$, the
left half of the left peak overlaps with the right half of the right peak.
Similarly for $k=-1$ and $k=-2$. For $|k| > 2$, there is no overlap. The fact
that we have overlaps at both even and odd shifts of $k$ means that we can't use
the same clever trick from before. However, what we do note is that the overlap
is always caused by opposite peaks (i.e. the left with the right peak, and never
the left with itself, or the right with itself). The solution then is to have
$B$ and $D$ have upper and lower passbands of opposite polarity, whil $A$ and
$C$ should have passbands of the same polarity.

Consider two prototype complex filters $P(z)$ and $Q(z)$ each with single
passbands going from $f_s/2M \rightarrow f_s/M$ (or $\frac{pi}{M} \rightarrow
\frac{2*pi}{M}$) - they must be complex to have support in only one half of the
frequency plane. Now say $P^*(z) = \sum_{r}p_r^*z^{-r}$ is the z-transform of
the conjugate of $p_r$, which has support only in the negative half of the
frequency plane. Then we can get the required filters by:

\begin{eqnarray}
A(z) &=& 2\Re [P(z)] = P(z) + P^*(z) \\
B(z) &=& 2\Im [P(z)] = -j[P(z) - P^*(z)] \\
C(z) &=& 2\Re [Q(z)] = Q(z) + Q^*(z) \\
D(z) &=& -2\Im [Q(z)] = j[Q(z) - Q^*(z)]
\end{eqnarray}

Then:
\begin{eqnarray}
A(W^kz)C(z) + B(W^kz)D(z) &=&  [P(W^kz) + P^*(W^kz)][Q(z) + Q^*(z)] + \nonumber \\
  && (-j*j)[P(W^kz) - P^*(W^kz)][Q(z) - Q^*(z)] \\
&=& P(W^kz)Q(z)[1+1] + P^*(W^kz)Q(z)[1-1] + \nonumber \\ 
  && P(W^kz)Q^*(z)[1-1] + P^*(W^kz)Q^*(z)[1+1] \\
&=& 2P(W^kz)Q(z) + 2P^*(W^kz)Q^*(z)
\end{eqnarray}

So now we only need to ensure that $P(W^kz)$ overlaps as little as possible with
$Q(z)$. This is somewhat more manageable, the diagram below shows the problem.

\begin{figure}
  \includegraphics[width=\textwidth]{\imgpath/overlaps_complex.png}
\end{figure}


\section{$\DTCWT$ Convolution}
To do full $\DTCWT$ convolution, we need to do more than the above. We don't
want to only keep some passbands, but we want to apply different gains to each
one. First, let us check that analytically this makes sense and we still won't
have aliasing when we do more general operations to the passbands. I.e. instead
of considering the above reduced tree, consider the below tree:

$$Y(z) = Y_{a}(z) + Y_{b}(z) = \frac{1}{M} \sum_{k=0}^{M-1} X(W^k z) [A(W^kz)G(W^kz^{M})C(z) + B(W^kz)H(W^kz^{M})D(z)]$$

If we set $H=G$ then we get:

$$Y(z) = Y_{a}(z) + Y_{b}(z) = \frac{1}{M} \sum_{k=0}^{M-1} X(W^k z)G(W^kz^{M}) [A(W^kz)C(z) + B(W^kz)D(z)]$$

And assuming the above analysis holds, we see that we are safe with aliasing, as
we know $[A(W^kz)C(z) + B(W^kz)D(z)] \approx 0$ for all $k\neq 0$. This means
that our equivalent filter becomes

\begin{eqnarray}
  Y(z) &=& \frac{1}{M} X(z)G(z^{M}) [A(z)C(z) + B(z)D(z)] \\
  &=& \frac{1}{M} X(z)G(z^{M}) [P(z)Q(z) + jP^{*}(z)Q^{*}(z)]
\end{eqnarray}

Now we know can assume that our $\DTCWT$ is well designed and extracts frequency
bands at local areas, then our filter $G(z^{M})$ allows us to modify these
passbands (e.g. by simply scaling if $G(z) = C$, or by more complex functions.


The output from \autoref{fig:dtcwt_two_tree} is:

$$ Y(z) = Y_a(z) + Y_b(z) = \frac{1}{M}\sum_{k=0}^{M-1} X\left(W^k z\right)
  \left[ A\left(W^kz\right)C(z) + B\left(W^kz\right)D(z) \right] $$

Where $W=e^{j2\pi/M}$.  To achieve shift invariance we need 
$A\left(W^kz\right)C(z) + B\left(W^kz\right)D(z)$ to be very small or to cancel
each other out for all $k \neq 0$.

The complex analysis filter (taking us into the wavelet domain) is 

$$P(z) = \frac{1}{2}\left(A(z)+jB(z)\right)$$

and the complex synthesis filter (returning us to the pixel domain) is 

$$Q(z) = \frac{1}{2}\left(C(z) - jD(z)\right)$$

where $A,B,C,D$ are real.  If $G(z) = G_r(z) + jG_i(z) = 1$ then the end-to-end
transfer function is (from section 4 of \cite{kingsbury_complex_2001}):

\begin{equation}\label{eq:end_to_end1}
\frac{Y(z)}{X(z)} = \frac{2}{M}\left(P(z)Q(z) + P^*(z)Q^*(z)\right)
\end{equation}

where $P, Q$ have support only in the top half of the Fourier plane and $P^*,
Q^*$ are $P$ and $Q$ reflected in the horizontal frequency axis. Examples of
$P(z)Q(z)$ for different subbands of a 2-D $\DTCWT$ have spectra shown in
\autoref{fig:dtcwt_bands_freq}, $P^*(z)Q^*(z)$ make up the missing half of the
frequency space.\\
\input{\path/figure1}

In a standard convolutional layer, an input with $C$ channels, $H$ rows and $W$
columns is $X \in \reals[C\x H\x W]$, which is then convolved with $F$ filters
of spatial size $K$ - $w \in \reals[F \x C\x K\x K]$, giving $Y \in \reals[F\x
H\x W]$. In many systems like \cite{krizhevsky_imagenet_2012, he_deep_2015}, the
first layer is typically a selection of bandpass filters, selecting edges with
different orientations and center frequencies. In the wavelet space this would
be trivial - take a decomposition of each input channel and keep individual
subbands (or equivalently, attenuate other bands), then take the inverse wavelet
transform.  \autoref{fig:ch6:dtcwt_bands} shows the frequency space for the
$\DTCWT$ and makes it clearer as to how this could be done practically for a two
scale transform. To attenuate all but say the $15 \degs$ band at the first scale
for the first input channel, we would need to have $13C$ gains for the 13
subbands and $C$ input channels, $13C-1$ of which would be zero and the
remaining coefficient one.

Instead of explicitly setting the gains, we can randomly initialize them and use
backpropagation to learn what they should be. This gives us the power to learn
more complex shapes rather than simple edges, as we can mix the regions of the
frequency space per input channel in an arbitrary way. 

\subsection{Forward propagation}
\autoref{fig:ch6:fwd_bwd} shows the block diagram using $Z$-transforms for
a single band of our system (it is based on Figure~4 in
\cite{kingsbury_complex_2001}). To keep things simple for the rest of
\autoref{sec:ch6:method} the figure shown is for a 1-D system; it is relatively
straightforward to extend this to 2-D\cite{selesnick_dual-tree_2005}. The
complex analysis filter (taking us into the wavelet domain) is $P(z)
= \frac{1}{2}\left(A(z)+jB(z)\right)$ and the complex synthesis filter
(returning us to the pixel domain) is $Q(z) = \frac{1}{2}\left(C(z)
  - jD(z)\right)$ where $A,B,C,D$ are real.  If $G(z) = G_r(z) + jG_i(z) = 1$
  then the end-to-end transfer function is (from section 4 of
\cite{kingsbury_complex_2001}):

\begin{equation}\label{eq:ch6:end_to_end1}
\frac{Y(z)}{X(z)} = \frac{2}{M}\left(P(z)Q(z) + P^*(z)Q^*(z)\right)
\end{equation}

where $P, Q$ have support only in the top half of the Fourier plane and $P^*,
Q^*$ are $P$ and $Q$ reflected in the horizontal frequency axis. Examples of
$P(z)Q(z)$ for different subbands of a 2-D $\DTCWT$ have spectra shown in
\autoref{fig:ch6:dtcwt_bands_freq}, $P^*(z)Q^*(z)$ make up the missing half of
the frequency space.\\ 

Modifying this from the standard wavelet equations by
adding the subband gains $G_r(z)$ and $G_i(z)$, the transfer function becomes:
\begin{equation}\label{eq:ch6:end_to_end2}
    \frac{Y(z)}{X(z)} = \frac{2}{M} \left[ \right. G_r(z^M) \left( P(z)Q(z) + P^*(z)Q^*(z) \right) +  
      \left. jG_i(z^M) \left(P(z)Q(z)-P^*(z)Q^*(z) \right) \right]
\end{equation}

\subsection{Backpropagation}
We start with the commonly known property that for a convolutional block, the
gradient with respect to the input is the gradient with respect to the output
convolved with the time reverse of the filter. More formally, if 
$Y(z) = H(z) X(z)$:
\begin{equation}\label{eq:ch6:backprop}
\Delta X(z) = H(z^{-1}) \Delta Y(z)
\end{equation}
where $H(z^{-1})$ is the $Z$-transform of the time/space reverse of $H(z)$,
$\Delta Y(z) \triangleq \dydx{L}{Y}(z)$ is the gradient of the loss with respect
to the output, and $\Delta X(z) \triangleq \dydx{L}{X}(z)$ is the gradient of
the loss with respect to the input. If H were complex, the first term in
\autoref{eq:ch6:backprop} would be $\bar{H}(1/\bar{z})$, but as each individual
block in the $\DTCWT$ is purely real, we can use the simpler form. 

Assume we already have access to the quantity $\Delta Y(z)$ (this is the input
to the backwards pass). \autoref{fig:ch6:bwd_pass} illustrates the
backpropagation procedure. An interesting result is that the backwards pass of
an inverse wavelet transform is equivalent to doing a forward wavelet
transform.\footnote{As shown in \autoref{fig:ch6:bwd_pass}, the analysis and
synthesis filters have to be swapped and time reversed. For orthogonal wavelet
transforms, the synthesis filters are already the time reverse of the analysis
filters, so no change has to be done. The q-shift filters of the $\DTCWT$
\cite{kingsbury_design_2003} have this property.} Similarly, the backwards pass
of the forward transform is equivalent to doing the inverse transform. The
weight update gradients are then calculated by finding 
$\Delta W(z) = \DTCWT\left\{ \Delta Y(z) \right\}$ and then convolving with the 
time reverse of the saved wavelet coefficients from the forward pass - $V(z)$.

\begin{gather}
  \Delta G_r(z) = \Delta W_r(z) V_r(z^{-1}) + \Delta W_i(z) V_i(z^{-1})  \label{eq:ch6:gr_update}\\
  \Delta G_i(z) =  -\Delta W_r(z) V_i(z^{-1}) + \Delta W_i(z) V_r(z^{-1})  \label{eq:ch6:gi_update} 
\end{gather}

Unsurprisingly, the passthrough gradients have similar form to
\autoref{eq:ch6:end_to_end2}:
\begin{equation}\label{eq:ch6:passthrough}
    \Delta X(z) = \frac{2\Delta Y(z)}{M} \left[G_r(z^{-M})\left( PQ + P^*Q^* \right)\right. + 
      \left. jG_i(z^{-M}) \left(PQ-P^*Q^* \right) \right] 
\end{equation}
where we have dropped the $z$ terms on $P(z), Q(z), P^*(z), Q^*(z)$ for brevity.

Note that we only need to evaluate equations
~\ref{eq:ch6:gr_update},\ref{eq:ch6:gi_update},\ref{eq:ch6:passthrough} over the
support of $G(z)$ i.e., if it is a single number we only need to calculate
$\left.\Delta G(z)\right\rvert_{z=0}$.


\subsection{Memory Cost}
Again considering a two scale transform --- instead of learning $w\in \reals[F
\x C\x K\x K]$ we learn complex gains at the two scales, and a real gain for the
real lowpass:

\begin{eqnarray*}
  g_1 &\in& \complexes[F\x C\x 6\x 1\x 1] \\
  g_2 &\in& \complexes[F\x C\x 6\x 1\x 1] \\
  g_{lp} &\in& \reals[F\x C\x 1\x 1]
\end{eqnarray*}

We have set the spatial dimension to be $1\x 1$ to show that this gain is
identical to a $1\x 1$ convolution over the complex wavelet coefficients. If we
wish, we can learn larger spatial sizes to have more complex
attenuation/magnification of the subbands. We also can use more/fewer than
2 wavelet scales.  At first glance, we have increased our parameterization by
a factor of 25 (13 subbands, of which all but the lowpass are complex), but
each one of these gains affects a large spatial size. For the first scale, the
effective size is about $5\x 5$ pixels, for the second scale it is about $15\x
15$.

\subsection{Computational Cost}
A standard convolutional layer needs $K^2 F$ multiplies per input pixel (of
which there are $C\x H\x W$). In comparison, the wavelet gain method does a set
number of operations per pixel for the forward and inverse transforms, and then
applies gains on subsampled activations. For a 2 level $\DTCWT$ the transform
overhead is about 60 multiplies for both the forward and inverse transform. It
is important to note that unlike the filtering operation, this does not scale
with $F$. The learned gains in each subband do scale with the number of output
channels, but can have smaller spatial size (as they have larger effective
sizes) as well as having fewer pixels to operate on (because of the decimation).
The end result is that as $F$ and $C$ grow, the overhead of the $C$ forward and
$F$ inverse transforms is outweighed by cost of $FC$ mixing processes, which
should in turn be significantly less than the cost of $FC$ $K\x K$ standard
convolutions for equivalent spatial sizes.

\input{\path/figure2}

\subsection{Examples}
\autoref{fig:ch6:example_impulses} show example impulse responses of our layer.
These impulses were generated by randomly initializing both the real and
imaginary parts of $g_2 \in \complexes[6\x 1\x 1]$ from $\mathcal{N}(0,1)$ and
$g_1, g_{lp}$ are set to 0. I.e. each shape has 12 random variables. It is good
to see that there is still a large degree of variability between shapes. Our
experiments have shown that the distribution of the normalized cross-correlation
between 512 of such randomly generated shapes matches the distribution for
random vectors with roughly 11.5 degrees of freedom.

