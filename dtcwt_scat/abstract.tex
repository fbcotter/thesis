The drive of this thesis is in exploring if wavelet theory, in
particular the $\DTCWT$, has any place in deep learning and if it does,
quantifying how beneficial it can be. The introduction of more powerful GPUs and
fast and popular deep learning frameworks such as PyTorch, Tensorflow and Caffe
in the past few years has helped the field of deep learning grow very rapidly.
Never before has it been so possible and so accessible to test new designs and
ideas for a machine learning algorithm than today. Despite this rapid growth,
there has been little interest in building wavelet analysis software in modern
frameworks.

This poses a challenge and an opportunity. To pave the way for more detailed
investigation (both in the rest of this thesis and by other researchers
who want to explore wavelets applied to deep learning), we must have the right
foundation and tools to facilitate research.

A good example of this is the current implementation of the ScatterNet. While
ScatterNets have been the most promising start in using wavelets in a deep
learning system, they have tended to be orders of magnitude slower, and significantly more
difficult to run than a standard convolutional network.

Additionally, any researchers wanting to explore the DWT in a deep learning
system have had to rewrite the filter bank implementation themselves, ensuring they
correctly handle boundary conditions and ensure correct filter tap alignment to
achieve perfect reconstruction.

\section{Chapter Layout}
This chapter describes how we have built a fast ScatterNet implementation in
PyTorch with the $\DTCWT$ as its wavelet transform. First we describe how to do an
efficient DWT in PyTorch in \autoref{sec:ch3:dwt} before showing how to expand this
to an efficient $\DTCWT$ in \autoref{sec:ch3:dtcwt}.
We then use the $\DTCWT$ to define our own ScatterNet in \autoref{sec:ch3:scat} (in
particular, see \autoref{alg:ch3:dtcwt_scat}). 
All of the code is available as an open-source library at \emph{PyTorch Wavelets} \cite{cotter_pytorch_2018}.

In parallel with our efforts, the original authors of the ScatterNet have
improved their implementation, making a new package called KyMatIO\cite{andreux_kymatio:_2018}. 
We compare the speed and classification performance of our package to KyMatIO in \autoref{sec:ch3:comparison}
as this provides some interesting insights into the choice of complex wavelet
for a ScatterNet. This is similar to the work of
\cite{singh_multi-resolution_2016}, where
\citeauthor{singh_multi-resolution_2016} show that a $\DTCWT$-ScatterNet
outperforms a Morlet-ScatterNet when used as a front end to an
SVM for some simpler classification tasks.
We find that our proposed $\DTCWT$-ScatterNet is 7 to 15 times faster 
than KyMatIO (depending on the padding style and wavelet length), as well as
giving a small improvement in performance when used as a front end to a CNN.
